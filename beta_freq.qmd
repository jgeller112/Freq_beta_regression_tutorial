---
title: "The Frequentist Way:  A Tutorial For Using Beta Regression in Pychological Research"
shorttitle: "Beta Regression Tutorial"
abstract: "Rates, percentages, and proportional data are widespread in psychology and social sciences. These data are usually analyzed with methods falling under the general linear model, which are not ideal for this type of data. A better alternative is the beta regession model which is based on the beta distribution. A beta regression can be used to model continuous outcomes that are non-normal,non-linear, heteroscedastic, and bounded between an upper and lower interval, such as proportions and percentiles. Thus, the beta regression model is well-suited to examine outcomes in psycholgical research expressed as proportions, percentages, or ratios. The overall purpose of this tutorial is to give researchers a hands-on demonstration of how to use beta regression using a real example from the psychological literature. First, we introduce the beta distribution and the beta regression model highlighting crucial components and assumptions. Second, we highlight how to conduct a beta regression in R  using an example dataset from the learning and memory literature. Some extensions of the beta model are then discussed (e.g., zero-inflated, zero- one-inflated, and ordered beta). We present accompanying R code throughout. All code to reproduce this paper can be found on Github: link forthcoming "
keywords: [beta regression, tutorial, psychology, learning and memory]
floatsintext: true
# Numbered lines (.pdf and .docx only)
numbered-lines: false
# File with references
suppress-title-page: false
# Link citations to references
link-citations: true
# Masks references that appear in the masked-citations list
mask: false
# Language options. See https://quarto.org/docs/authoring/language.html
lang: en
language:
  citation-last-author-separator: "and"
  citation-masked-author: "Masked Citation"
  citation-masked-date: "n.d."
  citation-masked-title: "Masked Title"
  email: "Email"
  title-block-author-note: "Author Note"
  title-block-correspondence-note: "Correspondence concerning this article should be addressed to"
  title-block-role-introduction: "Author roles were classified using the Contributor Role Taxonomy (CRediT; https://credit.niso.org/) as follows:"
bibliography: references.bib

format:
  html:
    theme:
      light: cosmo
      dark: darkly
    toc: true
    toc-depth: 3
    number-sections: true
    highlight-style: atom-one


execute:
  warning: false
  message: false

filters:
  - panelize
  - webr

knitr:
  opts_chunk:
    dev: "ragg_png"
---

::: callout-note
This document provides a practical overview of how to run beta regression models using a frequentist approach. It is intended as a companion to our article, *“A Beta Way: A Tutorial for Using Beta Regression in Psychological Research.”* For additional theoretical background, methodological details, and extended examples, readers should consult the full article. The present guide focuses specifically on the R packages and workflows available for fitting frequentist beta regression models.
:::

## Data and Methods

The principles of beta regression are best understood in the context of a real data set. The example we are gonna use comes from the learning and memory literature. A whole host of literature has shown extrinsic cues like fluency (i.e., how easy something is to process) can influence metamemory (i.e., how well we think we will remember something). As an interesting example, a line of research has focused on instructor fluency and how that influences both metamemory and actual learning. When an instructor uses lots of non-verbal gestures, has variable voice dynamics/intonation, is mobile about the space, and includes appropriate pauses when delivering content, participants perceive them as more fluent, but it does not influence actual memory performance, or what we learn from them [@carpenter2013; @toftness2017; @witherby2022]. While fluency of instructor has not been found to impact actual memory across several studies, @wilford2020 found that it can. In several experiments, @wilford2020 showed that when participants watched multiple videos of a fluent vs. a disfluent instructor (here two videos as opposed to one), they remembered more information on a final test. Given the interesting, and contradictory results, we chose this paper to highlight. In the current tutorial we are going to re-analyze the final recall data from Wilford et al. (2021; Experiment 1a). In the spirit of open science, the authors made their data available here:<https://osf.io/6tyn4/>.

Accuracy data is widely used in psychology and is well suited for Beta regression. Despite this, it is common to treat accuracy data as continuous and unbounded, and analyze the resulting proportions using methods that fall under the general linear model. Below we will reproduce the analysis conducted by @wilford2020 (Experiment 1a) and then re-analyze it using Beta regression. We hope to show how Beta regression and its extensions can be a more powerful tool in making inferences about your data.

In @wilford2020 (Expt 1a), they presented participants with two short videos highlighting two different concepts: (1) genetics of calico cats and (2) an explanation as to why skin wrinkles. Participants viewed either disfluent or fluent versions of these videos.[^1] For each video, metamemory was assessed using JOLs. JOLs require participants to rate an item on scale between 0-100 with 0 representing the item will not be remembered and a 100 representing they will definitely remember the item. In addition, other questions about the instructor were assessed and how much they learned. After a distractor task, a final free recall test was given were participants had to recall as much information about the video as they could in 3 minutes. Participants could score up to 10 points for each video. Here we will only being looking at the final recall data, but you could also analyze the JOL data with a beta regression.

[^1]: See an example of the fluent video here: <https://osf.io/hwzuk>. See an example of the disfluent video here: <https://osf.io/ra7be>.

## Reanalysis of Wilford et al. Experiment 1a

#### Load packages and data

As a first step, we will load the necessary packages along with the data we will be using. While we load all the necessary packages here, we also highlight when packages are needed as code chunks are run.

# Packages Needed

::: to-webr
```{r}
#| label: setup 
#| echo: true 
#| #| message: false 
#| #| warning: false

library(tidyverse) # tidy functions/data wrangling/viz 
library(glmmTMB) # zero inflated beta l
library(betareg) 
library(easystats)
library(easystats) 
library(gghalves) 
library(scales) # percentage 
library(tinytable) # tables l
library(marginaleffects) # marginal effects
options(scipen = 999) # get rid of scienitifc notation
```
:::

We will read in the data from GitHub:

::: to-webr
```{r}

fluency_data <- read_csv(
  "https://raw.githubusercontent.com/jgeller112/beta_regression_tutorial/refs/heads/main/manuscript/data/fluency_data.csv"
)
```
:::

## Beta regression approach

Using a traditional approach, we observed instructor fluency impacts actual learning. Keep in mind the traditional approach assumes normality of residuals and homoscadacity or constant variance. These assumptions are tricky to maintain when the continuous response approaches either the upper or lower boundary of the scale. 

One solution would be to run a beta regression model. Below we fit a beta regression using the `glmmTMB`package [@glmmTMB-4]. This a popular package for running maximum likelihood (MLE) beta regressions with and without varying intercepts/random effects. Other packages that can be used to run beta regression include `betareg` [@betareg] and also `gamlss` [@gamlss]. In `glmmTMB` we fit a beta regression by using a formula similar to the ols model we fit above. However, we must specify the `family` argument as `beta_family(link = "logit")` to fit a vanilla beta regression.

::: to-webr

```{r}
#| echo: true
#| error: true

beta_model <- glmmTMB(
  Accuracy ~ Fluency,
  disp = ~1,
  data = fluency_data,
  family = beta_family(link = "logit")
) # fits a constant for mu and dispersion
```
:::

When you run the above model, an error will appear: `Error in eval(family$initialize) : y values must be 0 < y < 1`. Do not worry! This is by design. If your remember, the beta distribution can only model responses in the interval \[0-1\], but not responses that are exactly 0 or 1. We need make sure there are no zeros and ones in our dataset.

::: to-webr

```{r}
#| label: tbl-01s
#| tbl-cap: Number of zeros and ones in our dataset
#| echo: false

fluency_data |>
  filter(Accuracy == 0 | Accuracy == 1) |> # get onlys 0s and 1s
  count(Accuracy) |> # count them
  tt()
```
:::
@tbl-01s shows we have 9 rows with accuracy of 0, and 1 row with an accuracy of exactly 1. To run a beta regression we will remove these values.

```{r}
#| echo: true
#|

#remove 0s and 1s
data_beta <- fluency_data |>
  filter(Accuracy != 0, Accuracy != 1)
```
:::

Let's fit the model again. The model object `data_beta` has our accuracy values modified.

::: to-webr

```{r}
#| echo: true

# fit beta model without 0s and 1s in our dataset
beta_model <- glmmTMB(
  Accuracy ~ Fluency,
  disp = ~1,
  data = data_beta,
  family = beta_family(link = "logit")
) # fits a constant for mu and dispersion
```
:::

No errors this time!

### Model parameters

@tbl-beta-cond provides a summary of the output for our Beta regression model. The $\mu$ parameter estimates, which have the conditional tag in the `Component` column while $\phi$ parameter coefficients are tagged as dispersion in the `Component` column).

#### $\mu$ component

::: to-webr

```{r}
#| label: tbl-beta-cond
#| tbl-cap: Model summary for the mu parameter in  beta regression model
#| tbl-cap-location: "top"
#| echo: false

# same latex issue with the underscores

beta_model_results <- model_parameters(beta_model)

beta_model_results |>
  as.data.frame() |>
  mutate(p = ifelse(p < .001, "<.001", round(p, 3))) |>
  tt(digits = 2)
```
::: to-webr


@tbl-beta-cond displays the summary of the Beta regression model. The first set of coefficients (first two rows in the table) represent how factors influence the $\mu$ parameter, which is the mean of the beta distribution. These coefficients are interpreted on the scale of the logit, meaning they represent linear changes on a nonlinear space. The intercept term `(Intercept)` represents the log odds of the mean on accuracy for the disfluent instructor condition. Here being in the disfluent condition translates to a log odds of `r round(beta_model_results$Coefficient[1], 3)`. The fluency coefficient `FluencyFluent` represents the difference between the fluency and disfluency conditions. That is, watching a fluent instructor does not lead to higher recall than watching a disfluent instructor, b = `r round(beta_model_results$Coefficient[2], 3)` , SE = `r round(beta_model_results$SE[2], 3)` , 95% CIs = \[`r round(beta_model_results$CI_low[2], 3)`,`r round(beta_model_results$CI_high[2], 3)`\], p = `r round(beta_model_results$p[2], 3)`.

##### Predicted probabilities
::: to-webr

```{r}
#| echo: true
# load marginaleffects package
library(marginaleffects)
```
:::

::: to-webr

```{r}
#| label: tbl-predict-prob
#| tbl-cap: Predicted probablities for fluency factor
#| tbl-cap-location: top
#| echo: false

# get the predicted probablities for each level of fluency
avg_predictions(beta_model, variables = "Fluency", dpar = "mu") |>
  tt(digits = 3) |>
  format_tt(j = "p", fn = scales::label_pvalue()) |>
  format_tt(escape = TRUE)
```
:::


@tbl-beta-cond displays the predicted probabilities for each condition. Both values in the estimate column are negative, which indicates that probability is below 50%. Looking at the predicted probabilities confirms this. For the `Fluency` factor, we can interpret the estimate column in terms of proportions or percentages. That is, participants who watched the fluent instructor scored on average 35% on the final exam compared to 30% for those who watched the disfluent instructor.

We can also easily visualize these from `marginaleffects` using the `plot_predictions` function. To visualize the `mu` parameter set the `what` argument as `mu`.

::: to-webr

```{r}
#| label: plot-beta
#| echo: true
beta_plot <- plot_predictions(beta_model, condition = "Fluency", vcov = TRUE)
```
:::

::: to-webr

```{r}
#| label: fig-plot-pre
#| echo: false
#| fig-cap: Predicted probablities for fluency factor

beta_plot +
  theme_lucid(base_size = 14) +
  scale_x_discrete(
    breaks = c("0", "1"),
    labels = c("Fluent", "Disfluent")
  ) +
  scale_y_continuous(labels = label_percent())
```
:::


##### Marginal effects

```{r}
#| label: ame1
#| echo: true
#| tbl-cap: Risk difference for fluency factor
#| tbl-cap-location: top

# get risk difference by default
beta_avg_comp <- avg_comparisons(beta_model, variables = "Fluency", dpar = "mu")
```

```{r}
#| label: tbl-ame1
#| echo: false
#| tbl-cap: Risk difference for fluency
beta_avg_comp |>
  # remove unwanted variables
  tt(digits = 2) |>
  format_tt(j = "p", fn = scales::label_pvalue()) |>
  format_tt(escape = TRUE)
```

@tbl-ame1 displays the risk difference for the fluency factor. The difference between the fluent and disfluent conditions is .06. That is, participants who watched a fluent instructor scored 6% higher on the final recall test than participants who watched the disfluent instructor, b= `r round(beta_avg_comp$estimate, 3)`, SE = `r round(beta_avg_comp$std.error, 3)`, 95 % CIs \[`r round(beta_avg_comp$conf.low, 3)`, `r round( beta_avg_comp$conf.high, 3)` \], p = `r round(beta_avg_comp$p.value, 3)`.

#### Precision ($\phi$) component

The other component we need to pay attention to is the dispersion or precision parameter coefficients labeled as `dispersion` under the `Component` column in @tbl-phi the dispersion ($\phi$) parameter tells us how precise our estimate is. Specifically, $\phi$ in beta regression tells us about the variability of the response variable around its mean. Specifically, a higher dispersion parameter indicates a narrower distribution, reflecting less variability. Conversely, a lower dispersion parameter suggests a wider distribution, reflecting greater variability. The main difference between a dispersion parameter and the variance is that the dispersion has a different interpretation depending on the value of the outcome, as we show below. The best way to understand dispersion is to examine visual changes in the distribution as the dispersion increases or decreases.

Understanding the dispersion parameter helps us gauge the precision of our predictions and the consistency of the response variable. In `beta_model` we only modeled the dispersion of the intercept. When $\phi$ is not specified, the intercept is modeled by default.

::: to-webr

```{r}
#| echo: true

# fit beta regression model using betareg

beta_model <- glmmTMB(
  Accuracy ~ Fluency,
  disp = ~1,
  data = data_beta,
  family = beta_family(link = "logit")
)
```
:::

::: to-webr

```{r}
#| label: tbl-phi
#| echo: false
#| tbl-cap: Beta model summary output of the $\phi$ parameter

# get the precision paramter
beta_model |>
  model_parameters() |>
  as.data.frame() |>
  rename(dfError = "df_error") |>
  filter(Component == "dispersion") |>
  tt(digits = 3)
```
:::

We can model the dispersion of the `Fluency` factor—this allows dispersion to differ between the fluent and disfluent conditions. To do this we add a `disp` argument to our `glmmTMB` function call. In the below model, `beta_model_dis`, we model the precision of the `Fluency` factor by using a `~` and adding factors of interest to the right of it

::: to-webr

```{r}
#| echo: true

# add disp/percison for fluency by including factors
beta_model_dis <- glmmTMB(
  Accuracy ~ Fluency,
  disp = ~Fluency, # phi for fluency_dummy
  data = data_beta,
  family = beta_family(link = "logit")
)
```
:::

::: to-webr

```{r}
#| label: phi-beta
#| echo: true

beta_model_dis_nonexp <- beta_model_dis |>
  model_parameters()
```
:::

```{r}
#| label: tbl-phi-beta
#| echo: false
#| tbl-cap: beta regression model summary for fluency factor with $\phi$ parameter

beta_model_dis_nonexp |>
  as.data.frame() |>
  mutate(p = ifelse(p < .001, "<.001", round(p, 3))) |>
  rename(dfError = "df_error") |>
  filter(Component == "dispersion") |>
  tt(digits = 3)


```

## Zero-inflated beta (ZIB) regression

A limitation of the beta regression model is it can can only model values between 0 and 1, but not exactly 0 or 1. In our dataset we have 9 rows with `Accuracy` equal to zero.

To use the Beta distribution we removed 0s and 1s--which is never a good idea in practice. In our case it might be important to model the structural zeros in our data, as fluency of instructor might be an important factor in predicting the zeros in our model. Luckily, there is a model called the zero-inflated beta (ZIB) model that takes into account the structural 0s in our data. We’ll still model the $\mu$ and $\phi$ (or mean and precision) of the beta distribution, but now we’ll also add one new special parameter: $\alpha$.

With zero-inflated regression, we’re actually modelling a mixture of the data-generating process. The $\alpha$ parameter uses a logistic regression to model whether the data is 0 or not. Substantively, this could be a useful model when we think that 0s come from a process that is relatively distinct from the data that is greater than 0. For example, if we had a dataset of how much teenagers smoke per week, we might want a separate model for the 0s because non-smokers are substantively different in that they never smoke, and first must choose to become smokers before we will record non-zero values.

Below we fit a model called `beta_model_0` using the `glmmTMB` package. In the `glmmTMB` function, we can model the zero inflation by including an argument called `ziformula`. This allows us to model the new parameter $\alpha$. Before we fit this model, we remove accuracy values equal to 1.
::: to-webr

```{r}
#| label: change 1s
#| echo: true
# keep 0 but transform 1 to .99
data_beta_0 <- fluency_data |>
  filter(Accuracy != 1)
```
:::


After we have done this, let's fit a model using our modified dataset (`data_beta_0` where there is a zero-inflated component for `Fluency`).
::: to-webr

```{r}
#| label: glmmTMB zib
#| echo: true

# fit zib modelwith glmmTMB

beta_model_0 <- glmmTMB(
  Accuracy ~ Fluency,
  disp = ~Fluency,
  ziformula = ~Fluency, # add zero inflated component to model
  data = data_beta_0,
  family = beta_family(link = "logit")
)
```
:::

### Model parameters
::: to-webr

```{r}
#| label: beta-model-zero
#| tbl-cap: Model summary for ZIB model
#| echo: false

# use model_parameters to get the summary coefs
model_zi <- model_parameters(beta_model_0)

```
:::

::: to-webr

```{r}
#| label: tbl-beta-model-zero
#| echo: false
#|

model_zi |>
  mutate(p = round(p, 3), p = ifelse(p == 0, "p < .001", p)) |>
  select(-Effects) |>
  tt(digits = 3)
```
::: 


@tbl-beta-model-zero provides a summary of the output for our zib model. As before, we can use the `model_paramters` function to extract the relevant coefficients.The $\mu$ parameter estimates, which have the conditional tag in the `Component` column are on the logit scale; while $\phi$ parameter coefficients (tagged as dispersion in the `Component` column) are on the log scale. In addition, the zero-inflated parameter estimates (tagged as zero-inflated in the `Component` column) are on the logit scale.

#### $\mu$

Looking at the $\mu$ part of the model, there is no significant effect for `Fluency`, b = `r round(model_zi$Coefficient[2], 3)` , SE = `r round(model_zi$SE[2], 3)` , 95% CIs = \[`r round(model_zi$CI_low[2], 3)`,`r round(model_zi$CI_high[2], 3)`\], p = `r round(model_zi$p[2], 3)`

#### $\alpha$

However, for the zero-inflated part of the model, the `Fluency` predictor is margianlly significant, b = `r round(model_zi$Coefficient[4], 3)` , SE = `r round(model_zi$SE[4], 3)` , 95% CIs = \[`r round(model_zi$CI_low[4], 3)`,`r round(model_zi$CI_high[4], 3)`\], p = `r round(model_zi$p[4], 3)`.

#### $\phi$

Lastly the dispersion estimate for `Fluency` is significant, b = `r round(model_zi$Coefficient[6], 3)` , SE = `r round(model_zi$SE[6], 3)` , 95% CIs = \[`r round(model_zi$CI_low[6], 3)`,`r round(model_zi$CI_high[6], 3)`\], p = `r round(model_zi$p[6], 3)`.

### Predicted probabilities and marginal effects

Similar to above, we can back-transform our estimates to get probabilities. Focusing on the zero-inflated part of our model (you can use prevuosuly highlighted code to get $\mu$ and $\phi$), we can use the `avg_predictions` function from `marginaleffects` package. Because we are interested in the zero-inflated part of the model we set the `type` argument to `zprob`.

::: to-webr

```{r}
#| label: zero-margeffects
#| tbl-cap: Predicted probablites (zero-inflated) for flueny factor
#| echo: true

beta_model_table <- beta_model_0 |>
  marginaleffects::avg_predictions(by = "Fluency", type = "zprob")
```
:::
::: to-webr

```{r}
#| label: tbl-predict-zero
#| echo: false

# get table for
beta_model_table |>
  as.data.frame() |>
  select(Fluency, estimate) |>
  tt(digits = 3)

```
:::

::: to-webr

```{r}
#| echo: true
#| label: marg-zib
#| tbl-cap: Risk difference (zero-inflated) for fluency

zob_marg <- beta_model_0 |>
  marginaleffects::avg_comparisons(
    variables = "Fluency",
    type = "zprob",
    comparison = "difference",
  )
```
:::

::: to-webr

```{r}
#| echo: false
#| label: tbl-marg-zib
# get table for
zob_marg |>
  as.data.frame() |>
  tt(digits = 3)

```
::: 


Interpreting the estimates in @tbl-marg-zib, seeing lecture videos with a fluent instructor reduces the proportion of zeros by about 13%, which is statistically significant, b = `r round(zob_marg$estimate, 3)` , SE = `r round(zob_marg$std.error, 3)` , 95% CIs = \[`r round(zob_marg$conf.low, 3)`,`r round(zob_marg$conf.high, 3)`\], p = `r round(zob_marg$p.value, 3)`. Here we have evidence that participants are more likely to do more poorly (have more zeros) after watching a disflueny lecture.

## Ordered Beta regression

We can run an ordered beta regression using the `glmmTMB` function and by changing the `family` argument to `ordbeta`.

::: to-webr

```{r}
#| label: run ordered beta regression
#|
ord_fit <- glmmTMB(
  formula = Accuracy ~ Fluency,
  data = fluency_data,
  family = ordbeta
)
```
:::

::: to-webr

```{r}
#| label: tbl-ordbeta-glmm
#| echo: false
#
ord_fit |>
  model_parameters() |>
  mutate(p = round(p, 2)) |>
  tt(digits = 2) |>
  format_tt(escape = TRUE)
```
::: 


#### Model Parameters

##### $\mu$

If we take a look at the summary output in @tbl-ordbeta-glmm, we can interpret the values similar to a beta regression, where the conditional effects are on the log odds scale. Here the `Fluency` parameter is not statistically significant, *p* = .05.

###### $\phi$

@tbl-ordbeta-glmm also includes an overall $\phi$ component. Similar to our other models we can model the variability as a function of fluency.

::: to-webr
```{r}
#| label: glmmtmb ordbeta

ord_fit_dis <- glmmTMB(
  formula = Accuracy ~ Fluency,
  disp = ~Fluency,
  data = fluency_data,
  family = ordbeta
)

```
::: 

::: to-webr

```{r}
#| label: tbl-ordbeta-glmm-disp
#| echo: false
ord_fit_dis |>
  model_parameters() |>
  mutate(p = round(p, 2)) |>
  tt(digits = 2) |>
  format_tt(escape = TRUE)
```
::: 


Similar to before, including the dispersion parameter introduces more uncertainty into the $\mu$ estimate.

#### Predicted probabilities and marginal effects

Remember these values are on the logit scale so we can take the inverse and get predicted probabilities like we have done before using the `marginaleffects` package. These values are shown in @tbl-ordbeta-pred.

We can get the risk difference as well. These values are in @tbl-ordbeta-risk.

### $\phi$

@tbl-ordbeta-summ also includes an overall phi component. Similar to our other models we can model the variability as a function of fluency. Let’s try this in our model: Note the addition of the `phi_reg` argument. This argument allows us to include a model that explicitly models the dispersion parameter. Because I am modeling $\phi$ as a function of fluency, I set the argument to `both`

In @tbl-phi-ordbeta, `b_phi_Fluency_dummy1` is close enough to 0 relative to its uncertainty, we can say that in this case there likely aren’t major differences in variance between the fluent disfluent conditions

## XBX Regression

A new type of regression known as XBX regression can be used for data that contain 0s and 1s.

```{r}
la_xbx <- betareg(Accuracy ~ Fluency | Fluency, data = fluency_data)
```

# References

<!-- References will auto-populate in the refs div below -->


## Sesssion Info

```{r}
sessionInfo()
```
